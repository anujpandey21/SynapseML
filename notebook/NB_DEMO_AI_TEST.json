{
	"name": "NB_DEMO_AI_TEST",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "5bc0dad2-a8af-49be-a730-611e7ac49e34"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "python"
			},
			"language_info": {
				"name": "python"
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"{\r\n",
					" \"cells\": [\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"dd4c8776-6853-4257-bef8-72778724ad57\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"# Azure OpenAI for Big Data\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"The Azure OpenAI service can be used to solve a large number of natural language tasks through prompting the completion API. To make it easier to scale your prompting workflows from a few examples to large datasets of examples we have integrated the Azure OpenAI service with the distributed machine learning library [SynapseML](https://www.microsoft.com/en-us/research/blog/synapseml-a-simple-multilingual-and-massively-parallel-machine-learning-library/). This integration makes it easy to use the [Apache Spark](https://spark.apache.org/) distributed computing framework to process millions of prompts with the OpenAI service. This tutorial shows how to apply large language models at a distributed scale using Azure Open AI and Azure Synapse Analytics. \\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"## Step 1: Prerequisites\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"The key prerequisites for this quickstart include a working Azure OpenAI resource, and an Apache Spark cluster with SynapseML installed. We suggest creating a Synapse workspace, but an Azure Databricks, HDInsight, or Spark on Kubernetes, or even a python environment with the `pyspark` package will work. \\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"1. An Azure OpenAI resource â€“ request access [here](https://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUOFA5Qk1UWDRBMjg0WFhPMkIzTzhKQ1dWNyQlQCN0PWcu) before [creating a resource](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource)\\n\",\r\n",
					"    \"1. [Create a Synapse workspace](https://docs.microsoft.com/en-us/azure/synapse-analytics/get-started-create-workspace)\\n\",\r\n",
					"    \"1. [Create a serverless Apache Spark pool](https://docs.microsoft.com/en-us/azure/synapse-analytics/get-started-analyze-spark#create-a-serverless-apache-spark-pool)\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"## Step 2: Import this guide as a notebook\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"The next step is to add this code into your Spark cluster. You can either create a notebook in your Spark platform and copy the code into this notebook to run the demo. Or download the notebook and import it into Synapse Analytics\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"1.\\t[Download this demo as a notebook](https://github.com/microsoft/SynapseML/blob/master/notebooks/features/cognitive_services/CognitiveServices%20-%20OpenAI.ipynb) (click Raw, then save the file)\\n\",\r\n",
					"    \"1.\\tImport the notebook [into the Synapse Workspace](https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-development-using-notebooks#create-a-notebook) or if using Databricks [into the Databricks Workspace](https://docs.microsoft.com/en-us/azure/databricks/notebooks/notebooks-manage#create-a-notebook)\\n\",\r\n",
					"    \"1. Install SynapseML on your cluster. Please see the installation instructions for Synapse at the bottom of [the SynapseML website](https://microsoft.github.io/SynapseML/). Note that this requires pasting an additional cell at the top of the notebook you just imported\\n\",\r\n",
					"    \"3.\\tConnect your notebook to a cluster and follow along, editing and rnnung the cells below.\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"## Step 3: Fill in your service information\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"Next, please edit the cell in the notebook to point to your service. In particular set the `service_name`, `deployment_name`, `location`, and `key` variables to match those for your OpenAI service:\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"1b0db8af-7fe2-40bc-9df4-cc7f274d53f0\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"import os\\n\",\r\n",
					"    \"from pyspark.sql import SparkSession\\n\",\r\n",
					"    \"from synapse.ml.core.platform import running_on_synapse, find_secret\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"# Bootstrap Spark Session\\n\",\r\n",
					"    \"spark = SparkSession.builder.getOrCreate()\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"if running_on_synapse():\\n\",\r\n",
					"    \"    from notebookutils.visualization import display\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"# Fill in the following lines with your service information\\n\",\r\n",
					"    \"service_name = \\\"synapseml-openai\\\"\\n\",\r\n",
					"    \"deployment_name = \\\"text-davinci-001\\\"\\n\",\r\n",
					"    \"deployment_name_embeddings = \\\"text-search-ada-doc-001\\\"\\n\",\r\n",
					"    \"deployment_name_embeddings_query = \\\"text-search-ada-query-001\\\"\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"key = find_secret(\\\"openai-api-key\\\")  # please replace this with your key as a string\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"assert key is not None and service_name is not None\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"76f069b7-14e8-44ea-97f0-1c49cf02eeed\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"## Step 4: Create a dataset of prompts\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"Next, create a dataframe consisting of a series of rows, with one prompt per row. \\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"You can also load data directly from ADLS or other databases. For more information on loading and preparing Spark dataframes, see the [Apache Spark data loading guide](https://spark.apache.org/docs/latest/sql-data-sources.html).\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"1a4366df-4d40-45a0-b1a7-6086b9c693d2\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    },\r\n",
					"    \"jupyter\": {\r\n",
					"     \"outputs_hidden\": false,\r\n",
					"     \"source_hidden\": false\r\n",
					"    },\r\n",
					"    \"nteract\": {\r\n",
					"     \"transient\": {\r\n",
					"      \"deleting\": false\r\n",
					"     }\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"df = spark.createDataFrame(\\n\",\r\n",
					"    \"    [\\n\",\r\n",
					"    \"        (\\\"Hello my name is\\\",),\\n\",\r\n",
					"    \"        (\\\"The best code is code thats\\\",),\\n\",\r\n",
					"    \"        (\\\"SynapseML is \\\",),\\n\",\r\n",
					"    \"    ]\\n\",\r\n",
					"    \").toDF(\\\"prompt\\\")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"fb48578c-e4b3-49fc-9ee2-2f8ae8808c19\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"## Step 5: Create the OpenAICompletion Apache Spark Client\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"To apply the OpenAI Completion service to your dataframe you just created, create an OpenAICompletion object which serves as a distributed client. Parameters of the service can be set either with a single value, or by a column of the dataframe with the appropriate setters on the `OpenAICompletion` object. Here we are setting `maxTokens` to 200. A token is around 4 characters, and this limit applies to the sum of the prompt and the result. We are also setting the `promptCol` parameter with the name of the prompt column in the dataframe.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"2dca7a9d-6092-48af-8653-10c141fd440d\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    },\r\n",
					"    \"jupyter\": {\r\n",
					"     \"outputs_hidden\": false,\r\n",
					"     \"source_hidden\": false\r\n",
					"    },\r\n",
					"    \"nteract\": {\r\n",
					"     \"transient\": {\r\n",
					"      \"deleting\": false\r\n",
					"     }\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"from synapse.ml.cognitive import OpenAICompletion\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"completion = (\\n\",\r\n",
					"    \"    OpenAICompletion()\\n\",\r\n",
					"    \"    .setSubscriptionKey(key)\\n\",\r\n",
					"    \"    .setDeploymentName(deployment_name)\\n\",\r\n",
					"    \"    .setUrl(\\\"https://{}.openai.azure.com/\\\".format(service_name))\\n\",\r\n",
					"    \"    .setMaxTokens(200)\\n\",\r\n",
					"    \"    .setPromptCol(\\\"prompt\\\")\\n\",\r\n",
					"    \"    .setErrorCol(\\\"error\\\")\\n\",\r\n",
					"    \"    .setOutputCol(\\\"completions\\\")\\n\",\r\n",
					"    \")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"64b2a454-65ab-45ec-9946-d92539899781\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"## Step 5: Transform the dataframe with the OpenAICompletion Client\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"Now that you have the dataframe and the completion client, you can transform your input dataset and add a column called `completions` with all of the information the service adds. We will select out just the text for simplicity.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"90684f9f-5c74-463f-a809-75a219489d7f\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"from pyspark.sql.functions import col\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"completed_df = completion.transform(df).cache()\\n\",\r\n",
					"    \"display(\\n\",\r\n",
					"    \"    completed_df.select(\\n\",\r\n",
					"    \"        col(\\\"prompt\\\"),\\n\",\r\n",
					"    \"        col(\\\"error\\\"),\\n\",\r\n",
					"    \"        col(\\\"completions.choices.text\\\").getItem(0).alias(\\\"text\\\"),\\n\",\r\n",
					"    \"    )\\n\",\r\n",
					"    \")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"d217c822-a213-43b3-aeba-2653e52b3421\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"Your output should look something like this. Please note completion text will be different\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"| **prompt**                 \\t| **error** \\t| **text**                                                                                                                              \\t|\\n\",\r\n",
					"    \"|-----------------------------\\t|-----------\\t|---------------------------------------------------------------------------------------------------------------------------------------\\t|\\n\",\r\n",
					"    \"| Hello my name is            \\t| null      \\t| Makaveli I'm eighteen years old and I want to   be a rapper when I grow up I love writing and making music I'm from Los   Angeles, CA \\t|\\n\",\r\n",
					"    \"| The best code is code thats \\t| null      \\t| understandable This is a subjective statement,   and there is no definitive answer.                                                   \\t|\\n\",\r\n",
					"    \"| SynapseML is                \\t| null      \\t| A machine learning algorithm that is able to learn how to predict the future outcome of events.                                       \\t|\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"9111da73-81f2-48e5-9a0c-eb65e1567f91\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"## Additional Usage Examples\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"### Improve throughput with request batching \\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"The example above makes several requests to the service, one for each prompt. To complete multiple prompts in a single request, use batch mode. First, in the OpenAICompletion object, instead of setting the Prompt column to \\\"Prompt\\\", specify \\\"batchPrompt\\\" for the BatchPrompt column.\\n\",\r\n",
					"    \"To do so, create a dataframe with a list of prompts per row.\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"**Note** that as of this writing there is currently a limit of 20 prompts in a single request, as well as a hard limit of 2048 \\\"tokens\\\", or approximately 1500 words.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"9f9b7953-6d96-4f83-b61d-c396cefb28ea\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    },\r\n",
					"    \"jupyter\": {\r\n",
					"     \"outputs_hidden\": false,\r\n",
					"     \"source_hidden\": false\r\n",
					"    },\r\n",
					"    \"nteract\": {\r\n",
					"     \"transient\": {\r\n",
					"      \"deleting\": false\r\n",
					"     }\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"batch_df = spark.createDataFrame(\\n\",\r\n",
					"    \"    [\\n\",\r\n",
					"    \"        ([\\\"The time has come\\\", \\\"Pleased to\\\", \\\"Today stocks\\\", \\\"Here's to\\\"],),\\n\",\r\n",
					"    \"        ([\\\"The only thing\\\", \\\"Ask not what\\\", \\\"Every litter\\\", \\\"I am\\\"],),\\n\",\r\n",
					"    \"    ]\\n\",\r\n",
					"    \").toDF(\\\"batchPrompt\\\")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"0bb5daf9-8155-460c-b2dd-e1ca302a3776\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"Next we create the OpenAICompletion object. Rather than setting the prompt column, set the batchPrompt column if your column is of type `Array[String]`.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"8411e5ba-7f22-4ac9-a78e-1746a7ccc8bc\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"batch_completion = (\\n\",\r\n",
					"    \"    OpenAICompletion()\\n\",\r\n",
					"    \"    .setSubscriptionKey(key)\\n\",\r\n",
					"    \"    .setDeploymentName(deployment_name)\\n\",\r\n",
					"    \"    .setUrl(\\\"https://{}.openai.azure.com/\\\".format(service_name))\\n\",\r\n",
					"    \"    .setMaxTokens(200)\\n\",\r\n",
					"    \"    .setBatchPromptCol(\\\"batchPrompt\\\")\\n\",\r\n",
					"    \"    .setErrorCol(\\\"error\\\")\\n\",\r\n",
					"    \"    .setOutputCol(\\\"completions\\\")\\n\",\r\n",
					"    \")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"be2a0d15-40e1-4a3d-a879-d7d0e0129b35\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"In the call to transform a request will then be made per row. Since there are multiple prompts in a single row, each request will be sent with all prompts in that row. The results will contain a row for each row in the request.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"a6fb7509-f582-47bd-8b57-f59d51c03eb3\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"completed_batch_df = batch_completion.transform(batch_df).cache()\\n\",\r\n",
					"    \"display(completed_batch_df)\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"2dd7259b-173a-41ef-b98e-7b1dc0df875f\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"### Using an automatic minibatcher\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"If your data is in column format, you can transpose it to row format using SynapseML's `FixedMiniBatcherTransformer`.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"04212778-8002-4e30-bf31-b7511c5776fd\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    },\r\n",
					"    \"jupyter\": {\r\n",
					"     \"outputs_hidden\": false,\r\n",
					"     \"source_hidden\": false\r\n",
					"    },\r\n",
					"    \"nteract\": {\r\n",
					"     \"transient\": {\r\n",
					"      \"deleting\": false\r\n",
					"     }\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"from pyspark.sql.types import StringType\\n\",\r\n",
					"    \"from synapse.ml.stages import FixedMiniBatchTransformer\\n\",\r\n",
					"    \"from synapse.ml.core.spark import FluentAPI\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"completed_autobatch_df = (\\n\",\r\n",
					"    \"    df.coalesce(\\n\",\r\n",
					"    \"        1\\n\",\r\n",
					"    \"    )  # Force a single partition so that our little 4-row dataframe makes a batch of size 4, you can remove this step for large datasets\\n\",\r\n",
					"    \"    .mlTransform(FixedMiniBatchTransformer(batchSize=4))\\n\",\r\n",
					"    \"    .withColumnRenamed(\\\"prompt\\\", \\\"batchPrompt\\\")\\n\",\r\n",
					"    \"    .mlTransform(batch_completion)\\n\",\r\n",
					"    \")\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"display(completed_autobatch_df)\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"f1611cd5-1af9-458f-a1d5-b1f517194cc8\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"### Prompt engineering for translation\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"The Azure OpenAI service can solve many different natural language tasks through [prompt engineering](https://docs.microsoft.com/en-us/azure/cognitive-services/openai/how-to/completions). Here we show an example of prompting for language translation:\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"0cee629b-240d-411f-a067-9f7b9ac6ce5d\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"translate_df = spark.createDataFrame(\\n\",\r\n",
					"    \"    [\\n\",\r\n",
					"    \"        (\\\"Japanese: Ookina hako \\\\nEnglish: Big box \\\\nJapanese: Midori tako\\\\nEnglish:\\\",),\\n\",\r\n",
					"    \"        (\\n\",\r\n",
					"    \"            \\\"French: Quel heure et il au Montreal? \\\\nEnglish: What time is it in Montreal? \\\\nFrench: Ou est le poulet? \\\\nEnglish:\\\",\\n\",\r\n",
					"    \"        ),\\n\",\r\n",
					"    \"    ]\\n\",\r\n",
					"    \").toDF(\\\"prompt\\\")\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"display(completion.transform(translate_df))\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"3a726683-8e19-4ebf-8244-bde82ec4fdbe\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"source\": [\r\n",
					"    \"### Prompt for question answering\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"Here, we prompt GPT-3 for general-knowledge question answering:\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {\r\n",
					"    \"application/vnd.databricks.v1+cell\": {\r\n",
					"     \"inputWidgets\": {},\r\n",
					"     \"nuid\": \"831abdac-4b6c-4b7d-b99a-43dcb75c4169\",\r\n",
					"     \"showTitle\": false,\r\n",
					"     \"title\": \"\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"qa_df = spark.createDataFrame(\\n\",\r\n",
					"    \"    [\\n\",\r\n",
					"    \"        (\\n\",\r\n",
					"    \"            \\\"Q: Where is the Grand Canyon?\\\\nA: The Grand Canyon is in Arizona.\\\\n\\\\nQ: What is the weight of the Burj Khalifa in kilograms?\\\\nA:\\\",\\n\",\r\n",
					"    \"        )\\n\",\r\n",
					"    \"    ]\\n\",\r\n",
					"    \").toDF(\\\"prompt\\\")\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"display(completion.transform(qa_df))\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"# OpenAI Embeddings\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"We will use t-SNE to reduce the dimensionality of the embeddings from 1536 to 2. Once the embeddings are reduced to two dimensions, we can plot them in a 2D scatter plot.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"from synapse.ml.cognitive import OpenAIEmbedding\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"embedding = (\\n\",\r\n",
					"    \"    OpenAIEmbedding()\\n\",\r\n",
					"    \"    .setSubscriptionKey(key)\\n\",\r\n",
					"    \"    .setDeploymentName(deployment_name_embeddings)\\n\",\r\n",
					"    \"    .setUrl(\\\"https://{}.openai.azure.com/\\\".format(service_name))\\n\",\r\n",
					"    \"    .setTextCol(\\\"combined\\\")\\n\",\r\n",
					"    \"    .setErrorCol(\\\"error\\\")\\n\",\r\n",
					"    \"    .setOutputCol(\\\"embeddings\\\")\\n\",\r\n",
					"    \")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"import pyspark.sql.functions as F\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"df = spark.read.options(inferSchema=\\\"True\\\", delimiter=\\\",\\\", header=True).csv(\\n\",\r\n",
					"    \"    \\\"wasbs://publicwasb@mmlspark.blob.core.windows.net/fine_food_reviews_1k.csv\\\"\\n\",\r\n",
					"    \")\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"df = df.withColumn(\\n\",\r\n",
					"    \"    \\\"combined\\\",\\n\",\r\n",
					"    \"    F.format_string(\\\"Title: %s; Content: %s\\\", F.trim(df.Summary), F.trim(df.Text)),\\n\",\r\n",
					"    \")\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"display(df)\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"from pyspark.sql.functions import col\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"completed_df = embedding.transform(df).cache()\\n\",\r\n",
					"    \"display(completed_df)\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Retrieve embeddings\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"import numpy as np\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"matrix = np.array(completed_df.select(\\\"embeddings\\\").collect())[:, 0, :]\\n\",\r\n",
					"    \"matrix.shape\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Reduce dimensionality\\n\",\r\n",
					"    \"We reduce the dimensionality to 2 dimensions using t-SNE decomposition.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"import pandas as pd\\n\",\r\n",
					"    \"from sklearn.manifold import TSNE\\n\",\r\n",
					"    \"import numpy as np\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"# Create a t-SNE model and transform the data\\n\",\r\n",
					"    \"tsne = TSNE(\\n\",\r\n",
					"    \"    n_components=2, perplexity=15, random_state=42, init=\\\"random\\\", learning_rate=200\\n\",\r\n",
					"    \")\\n\",\r\n",
					"    \"vis_dims = tsne.fit_transform(matrix)\\n\",\r\n",
					"    \"vis_dims.shape\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Plot the embeddings\\n\",\r\n",
					"    \"We colour each review by its star rating, ranging from red for negative reviews, to green for positive reviews..\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"We can observe a decent data separation even in the reduced 2 dimensions.\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"import matplotlib.pyplot as plt\\n\",\r\n",
					"    \"import matplotlib\\n\",\r\n",
					"    \"import numpy as np\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"scores = np.array(completed_df.select(\\\"Score\\\").collect()).reshape(-1)\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"colors = [\\\"red\\\", \\\"darkorange\\\", \\\"gold\\\", \\\"turquoise\\\", \\\"darkgreen\\\"]\\n\",\r\n",
					"    \"x = [x for x, y in vis_dims]\\n\",\r\n",
					"    \"y = [y for x, y in vis_dims]\\n\",\r\n",
					"    \"color_indices = scores - 1\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"colormap = matplotlib.colors.ListedColormap(colors)\\n\",\r\n",
					"    \"plt.scatter(x, y, c=color_indices, cmap=colormap, alpha=0.3)\\n\",\r\n",
					"    \"for score in [0, 1, 2, 3, 4]:\\n\",\r\n",
					"    \"    avg_x = np.array(x)[scores - 1 == score].mean()\\n\",\r\n",
					"    \"    avg_y = np.array(y)[scores - 1 == score].mean()\\n\",\r\n",
					"    \"    color = colors[score]\\n\",\r\n",
					"    \"    plt.scatter(avg_x, avg_y, marker=\\\"x\\\", color=color, s=100)\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"plt.title(\\\"Amazon ratings visualized in language using t-SNE\\\")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Use embeddings to build a semantic search Index\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"Note that for some OpenAI models, users should use separate models for embedding documents and queries. These models are denoted by the \\\"-doc\\\" and \\\"-query\\\" suffixes respectively. \"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"embedding_query = (\\n\",\r\n",
					"    \"    OpenAIEmbedding()\\n\",\r\n",
					"    \"    .setSubscriptionKey(key)\\n\",\r\n",
					"    \"    .setDeploymentName(deployment_name_embeddings_query)\\n\",\r\n",
					"    \"    .setUrl(\\\"https://{}.openai.azure.com/\\\".format(service_name))\\n\",\r\n",
					"    \"    .setTextCol(\\\"query\\\")\\n\",\r\n",
					"    \"    .setErrorCol(\\\"error\\\")\\n\",\r\n",
					"    \"    .setOutputCol(\\\"embeddings\\\")\\n\",\r\n",
					"    \")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Create a dataframe of search queries\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"Note: The data types of the ID columns in the document and query dataframes should be the same\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"query_df = (\\n\",\r\n",
					"    \"    spark.createDataFrame(\\n\",\r\n",
					"    \"        [\\n\",\r\n",
					"    \"            (\\n\",\r\n",
					"    \"                0,\\n\",\r\n",
					"    \"                \\\"desserts\\\",\\n\",\r\n",
					"    \"            ),\\n\",\r\n",
					"    \"            (\\n\",\r\n",
					"    \"                1,\\n\",\r\n",
					"    \"                \\\"disgusting\\\",\\n\",\r\n",
					"    \"            ),\\n\",\r\n",
					"    \"        ]\\n\",\r\n",
					"    \"    )\\n\",\r\n",
					"    \"    .toDF(\\\"id\\\", \\\"query\\\")\\n\",\r\n",
					"    \"    .withColumn(\\\"id\\\", F.col(\\\"id\\\").cast(\\\"int\\\"))\\n\",\r\n",
					"    \")\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Generate embeddings for queries\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"completed_query_df = embedding_query.transform(query_df).cache()\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Build index for fast retrieval\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"from synapse.ml.nn import *\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"knn = (\\n\",\r\n",
					"    \"    KNN()\\n\",\r\n",
					"    \"    .setFeaturesCol(\\\"embeddings\\\")\\n\",\r\n",
					"    \"    .setValuesCol(\\\"id\\\")\\n\",\r\n",
					"    \"    .setOutputCol(\\\"output\\\")\\n\",\r\n",
					"    \"    .setK(10)\\n\",\r\n",
					"    \")  # top-k for retrieval\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"knn_index = knn.fit(completed_df)\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"markdown\",\r\n",
					"   \"metadata\": {},\r\n",
					"   \"source\": [\r\n",
					"    \"## Retrieve results\"\r\n",
					"   ]\r\n",
					"  },\r\n",
					"  {\r\n",
					"   \"cell_type\": \"code\",\r\n",
					"   \"execution_count\": null,\r\n",
					"   \"metadata\": {},\r\n",
					"   \"outputs\": [],\r\n",
					"   \"source\": [\r\n",
					"    \"df_matches = knn_index.transform(completed_query_df).cache()\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"df_result = (\\n\",\r\n",
					"    \"    df_matches.withColumn(\\\"match\\\", F.explode(\\\"output\\\"))\\n\",\r\n",
					"    \"    .join(df, df[\\\"id\\\"] == F.col(\\\"match.value\\\"))\\n\",\r\n",
					"    \"    .select(\\\"query\\\", F.col(\\\"combined\\\"), \\\"match.distance\\\")\\n\",\r\n",
					"    \")\\n\",\r\n",
					"    \"\\n\",\r\n",
					"    \"display(df_result)\"\r\n",
					"   ]\r\n",
					"  }\r\n",
					" ],\r\n",
					" \"metadata\": {\r\n",
					"  \"application/vnd.databricks.v1+notebook\": {\r\n",
					"   \"dashboards\": [],\r\n",
					"   \"language\": \"python\",\r\n",
					"   \"notebookMetadata\": {\r\n",
					"    \"pythonIndentUnit\": 2\r\n",
					"   },\r\n",
					"   \"notebookName\": \"CognitiveServices - OpenAI\",\r\n",
					"   \"notebookOrigID\": 446901528076027,\r\n",
					"   \"widgets\": {}\r\n",
					"  },\r\n",
					"  \"kernel_info\": {\r\n",
					"   \"name\": \"synapse_pyspark\"\r\n",
					"  },\r\n",
					"  \"kernelspec\": {\r\n",
					"   \"display_name\": \"Python 3 (ipykernel)\",\r\n",
					"   \"language\": \"python\",\r\n",
					"   \"name\": \"python3\"\r\n",
					"  },\r\n",
					"  \"language_info\": {\r\n",
					"   \"codemirror_mode\": {\r\n",
					"    \"name\": \"ipython\",\r\n",
					"    \"version\": 3\r\n",
					"   },\r\n",
					"   \"file_extension\": \".py\",\r\n",
					"   \"mimetype\": \"text/x-python\",\r\n",
					"   \"name\": \"python\",\r\n",
					"   \"nbconvert_exporter\": \"python\",\r\n",
					"   \"pygments_lexer\": \"ipython3\",\r\n",
					"   \"version\": \"3.8.8\"\r\n",
					"  },\r\n",
					"  \"save_output\": true,\r\n",
					"  \"synapse_widget\": {\r\n",
					"   \"state\": {\r\n",
					"    \"4bd0e60b-98ae-4bfe-98ee-6f0399ceb456\": {\r\n",
					"     \"persist_state\": {\r\n",
					"      \"view\": {\r\n",
					"       \"chartOptions\": {\r\n",
					"        \"aggregationType\": \"count\",\r\n",
					"        \"categoryFieldKeys\": [\r\n",
					"         \"0\"\r\n",
					"        ],\r\n",
					"        \"chartType\": \"bar\",\r\n",
					"        \"isStacked\": false,\r\n",
					"        \"seriesFieldKeys\": [\r\n",
					"         \"0\"\r\n",
					"        ]\r\n",
					"       },\r\n",
					"       \"tableOptions\": {},\r\n",
					"       \"type\": \"details\"\r\n",
					"      }\r\n",
					"     },\r\n",
					"     \"sync_state\": {\r\n",
					"      \"isSummary\": false,\r\n",
					"      \"language\": \"scala\",\r\n",
					"      \"table\": {\r\n",
					"       \"rows\": [\r\n",
					"        {\r\n",
					"         \"0\": \"Once upon a time\",\r\n",
					"         \"1\": [\r\n",
					"          \" there was a girl who had a dream of becoming a writer.\\n\\nShe started writing short stories\"\r\n",
					"         ]\r\n",
					"        },\r\n",
					"        {\r\n",
					"         \"0\": \"Hello my name is\",\r\n",
					"         \"1\": [\r\n",
					"          \"***** and I have a question about my cat\\n\\nHello, thank you for bringing your question to\"\r\n",
					"         ]\r\n",
					"        },\r\n",
					"        {\r\n",
					"         \"0\": \"The best code is code thats\",\r\n",
					"         \"1\": [\r\n",
					"          \" not there\\n\\nCommenting your code is important. Not only does it help you remember what you\"\r\n",
					"         ]\r\n",
					"        }\r\n",
					"       ],\r\n",
					"       \"schema\": [\r\n",
					"        {\r\n",
					"         \"key\": \"0\",\r\n",
					"         \"name\": \"prompt\",\r\n",
					"         \"type\": \"string\"\r\n",
					"        },\r\n",
					"        {\r\n",
					"         \"key\": \"1\",\r\n",
					"         \"name\": \"text\",\r\n",
					"         \"type\": \"ArrayType(StringType,true)\"\r\n",
					"        }\r\n",
					"       ],\r\n",
					"       \"truncated\": false\r\n",
					"      }\r\n",
					"     },\r\n",
					"     \"type\": \"Synapse.DataFrame\"\r\n",
					"    }\r\n",
					"   },\r\n",
					"   \"version\": \"0.1\"\r\n",
					"  }\r\n",
					" },\r\n",
					" \"nbformat\": 4,\r\n",
					" \"nbformat_minor\": 1\r\n",
					"}\r\n",
					""
				]
			}
		]
	}
}